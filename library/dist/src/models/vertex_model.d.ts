import { GenerativeModel } from "@google-cloud/vertexai";
import { Model } from "./model";
import { Static, TSchema } from "@sinclair/typebox";
/**
 * Class to interact with models available through Google Cloud's Model Garden.
 */
export declare class VertexModel extends Model {
  private vertexAI;
  private modelName;
  private limit;
  /**
   * Create a model object.
   * @param project - the Google Cloud Project ID, not the numberic project name
   * @param location - The Google Cloud Project location
   * @param modelName - the name of the model from Vertex AI's Model Garden to connect with, see
   * the full list here: https://cloud.google.com/model-garden
   */
  constructor(project: string, location: string, modelName?: string);
  /**
   * Get generative model corresponding to structured data output specification as a JSON Schema specification.
   */
  getGenerativeModel(schema?: TSchema): GenerativeModel;
  /**
   * Generate text based on the given prompt.
   * @param prompt the text including instructions and/or data to give the model
   * @returns the model response as a string
   */
  generateText(prompt: string): Promise<string>;
  /**
   * Generate structured data based on the given prompt.
   * @param prompt the text including instructions and/or data to give the model
   * @param schema a JSON Schema specification (generated from TypeBox)
   * @returns the model response as data structured according to the JSON Schema specification
   */
  generateData(prompt: string, schema: TSchema): Promise<Static<typeof schema>>;
  /**
   * Calls an LLM to generate text based on a given prompt and handles rate limiting, response validation and retries.
   *
   * Concurrency: To take advantage of concurrent execution, invoke this function as a batch of callbacks,
   * and pass it to the `executeConcurrently` function. It will run multiple `callLLM` functions concurrently,
   * up to the limit set by `p-limit` in `VertexModel`'s constructor.
   *
   * @param prompt - The text prompt to send to the language model.
   * @param model - The specific language model that will be called.
   * @param validator - optional check for the model response.
   * @returns A Promise that resolves with the text generated by the language model.
   */
  callLLM(
    prompt: string,
    model: GenerativeModel,
    validator?: (response: string) => boolean
  ): Promise<string>;
}
