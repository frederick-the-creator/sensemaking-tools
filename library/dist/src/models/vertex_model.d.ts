import { GenerativeModel } from "@google-cloud/vertexai";
import { Model } from "./model";
import { Static, TSchema } from "@sinclair/typebox";
/**
 * Class to interact with models available through Google Cloud's Model Garden.
 */
export declare class VertexModel extends Model {
    private vertexAI;
    private modelName;
    private limit;
    /**
     * Create a model object.
     * @param project - the Google Cloud Project ID, not the numberic project name
     * @param location - The Google Cloud Project location
     * @param modelName - the name of the model from Vertex AI's Model Garden to connect with, see
     * the full list here: https://cloud.google.com/model-garden
     */
    constructor(project: string, location: string, modelName?: string);
    /**
     * Get generative model corresponding to structured data output specification as a JSON Schema specification.
     */
    getGenerativeModel(schema?: TSchema): GenerativeModel;
    /**
     * Generate text based on the given prompt.
     * @param prompt the text including instructions and/or data to give the model
     * @returns the model response as a string
     */
    generateText(prompt: string): Promise<string>;
    /**
     * Generate structured data based on the given prompt.
     * @param prompt the text including instructions and/or data to give the model
     * @param schema a JSON Schema specification (generated from TypeBox)
     * @returns the model response as data structured according to the JSON Schema specification
     */
    generateData(prompt: string, schema: TSchema): Promise<Static<typeof schema>>;
    /**
     * Calls an LLM to generate text based on a given prompt and handles rate limiting, response validation and retries.
     *
     * Concurrency: To take advantage of concurrent execution, invoke this function as a batch of callbacks,
     * and pass it to the `executeConcurrently` function. It will run multiple `callLLM` functions concurrently,
     * up to the limit set by `p-limit` in `VertexModel`'s constructor.
     *
     * @param prompt - The text prompt to send to the language model.
     * @param model - The specific language model that will be called.
     * @param validator - optional check for the model response.
     * @returns A Promise that resolves with the text generated by the language model.
     */
    callLLM(prompt: string, model: GenerativeModel, validator?: (response: string) => boolean): Promise<string>;
}
